 _Hi, I'm latika! ğŸ‘‹ This is my Capston Project ğŸ¯!_

## ğŸ¦· Forensic Dentistry: Using Dental Metrics to Predict Gender



## ğŸ“– Project Overview
Forensic dentistry is a branch of forensic medicine that helps identify individuals using dental measurements. This project utilizes **machine learning** techniques to predict **gender** based on dental metrics.

## ğŸš€ Tech Stack
- **Programming Language**: Python
- **Tools**: Jupyter Notebook, Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, XGBoost
- **Project Difficulty level** : Rookie/ Basic
## ğŸ¯ Objectives
- **Analyze** dental data and its relationship with gender.
- **Implement machine learning models** for gender classification.
- **Evaluate and compare model performance**.

## ğŸ“‚ Dataset Description
**File:** `Dentistry Dataset.csv`

| Feature Name                           | Description |
|----------------------------------------|-------------|
| **Age**                                | The age of the individual |
| **Gender (Target Variable)**           | Male (1) / Female (0) |
| **Inter-canine distance intraoral**    | Measurement between upper canine teeth |
| **Right & Left Canine Width Casts**    | Width of the right and left canines |
| **Canine Index**                       | Canine index measurement |

## ğŸ›  Methodology
### 1ï¸âƒ£ **Data Preprocessing**
```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, Normalizer

# Load dataset
df = pd.read_csv("Dentistry Dataset.csv")

# Handle missing values
df.fillna(df.mean(), inplace=True)

# Encode categorical data
label_encoder = LabelEncoder()
df['Gender'] = label_encoder.fit_transform(df['Gender'])

# Normalize features
normalizer = Normalizer()
df.iloc[:, 2:] = normalizer.fit_transform(df.iloc[:, 2:])
```

### 2ï¸âƒ£ **Exploratory Data Analysis (EDA)**
```python
import seaborn as sns
import matplotlib.pyplot as plt

# Heatmap for correlation analysis
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.show()
```

### 3ï¸âƒ£ **Model Building**
```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score

# Splitting dataset
X = df.drop(columns=['Gender'])
y = df['Gender']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model
model = XGBClassifier()
model.fit(X_train, y_train)

# Model evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
```

## ğŸ“Š Results & Analysis
| Model                  | Accuracy |
|------------------------|-------------|
| Logistic Regression    | 0.64090909090909         |
| Decision Tree         | 0.877272727272727         |
| Random Forest        | 0.895454545454545         |
| XGBoost             |     0.9         |

ğŸ“Œ **Best Performing Model:** _XGBoost (XX% Accuracy)_

## ğŸ“¢ Conclusion & Future Work
- **XGBoost performed the best**, showing potential for forensic applications.
- **Future work:** More diverse datasets, deep learning techniques, real-world testing.

## ğŸ“‚ Installation & Usage
### ğŸ”¹ **Clone the Repository**
```bash
git clone https://github.com/Saurabhji-1/Capstone-Project/tree/main
```

### ğŸ”¹ **Install Dependencies**
```bash
!pip install numpy pandas matplotlib seaborn scikit-learn xgboost

```

### ğŸ”¹ **Run the Jupyter Notebook**
```bash
jupyter notebook
```

## ğŸ“‚ References
- **Scikit-learn Documentation**: [https://scikit-learn.org](https://scikit-learn.org)
- **XGBoost Documentation**: [https://xgboost.readthedocs.io](https://xgboost.readthedocs.io)

---

ğŸ“Œ **Author:** _**Saurabh Sharma**_  

ğŸ“Œ **GitHub Repository:** _https://github.com/Saurabhji-1?tab=repositories_

